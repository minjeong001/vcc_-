# ğŸ’¡ ì‹œê°ì¥ì• ì¸ì„ ìœ„í•œ ì‡¼í•‘ì¹´íŠ¸ ë³´ì¡°ê¸°ê¸°

## âœï¸ í”„ë¡œì íŠ¸ ê°œìš”
 ì‡¼í•‘ì€ ì¼ìƒì—ì„œ ë¹ ì§ˆ ìˆ˜ ì—†ëŠ” í™œë™ì´ì§€ë§Œ, ì‹œê°ì¥ì• ì¸ì—ê²ŒëŠ” ì´ëŸ° ì¼ìƒìƒí™œ ì†ì—ë„ ì–´ë ¤ì›€ê³¼ ë¶ˆí¸í•¨ì´ ìˆìŒì„ ì¸ì‹í•¨. **ê¸°ì¡´ ì‡¼í•‘ì¹´íŠ¸ì— íƒˆë¶€ì°© ê°€ëŠ¥í•œ ë³´ì¡° ëª¨ë“ˆ**ì„ ì œê³µí•¨ìœ¼ë¡œì¨, ì‹œê°ì¥ì• ì¸ì´ íƒ€ì¸ì˜ ë„ì›€ ì—†ì´ **ë…ë¦½ì ìœ¼ë¡œ ì‡¼í•‘ì„ ìˆ˜í–‰**í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” ì œí’ˆ ê°œë°œì„ ëª©ì ìœ¼ë¡œ í•¨.

---
## ğŸ›’ ì „ì²´ êµ¬ì¡° ì„¤ê³„ë„
![ì œì‘í•  ì œí’ˆì˜ ì „ì²´ êµ¬ì„±ë„](all.png)

- ì¹´íŠ¸ ì˜†ë©´ : Raspberry pi ì´ìš© - ì¹´ë©”ë¼, í‘¸ì‹œë²„íŠ¼, usb ì‚¬ìš´ë“œ ì¹´ë“œ, ì´ì–´í°, ë³´ì¡°ë°°í„°ë¦¬ ì‚¬ìš©
- ì¹´íŠ¸ ì•ë©´ (ì†¡ì‹ ë¶€) : Arduino uno ì´ìš© - VL53L0X ê±°ë¦¬ì„¼ì„œ, NRF24L01 ì‹ í˜¸ ì†¡ì‹  ëª¨ë“ˆ,NRF24L01 ì–´ëŒ‘í„°, AAê±´ì „ì§€(4ê°œ), ìŠ¤ìœ„ì¹˜ ì‚¬ìš©
- ì†ëª© ë°´ë“œ (ìˆ˜ì‹ ë¶€): Arduino nano ì´ìš© - NRF24L01 ì‹ í˜¸ ìˆ˜ì‹  ëª¨ë“ˆ, NRF24L01 ì–´ëŒ‘í„°, ì§„ë™ëª¨í„°, ë¦¬íŠ¬ì´ì˜¨ ë°°í„°ë¦¬, ì¶©ì „ ìŠ¹ì••ê¸°, ìŠ¤ìœ„ì¹˜ 2ê°œ (ì§„ë™ ë° ì „ì›) 

---
## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥ (1~4)
### **Raspberry pi + Arduino**ë¥¼ ì´ìš©í•œ ê¸°ëŠ¥
 - Raspberry pië¥¼ í†µí•´ **ìƒí’ˆ ì¸ì‹, ìµœì €ê°€ ë¹„êµ, ë„ì›€ìš”ì²­** ê¸°ëŠ¥ì„ ì¶”ê°€
 - Arduinoë¥¼ ì´ìš©í•´ **ì¥ì• ë¬¼ ê°ì§€** ê¸°ëŠ¥ì„ ì¶”ê°€

**Raspberry pi bread board view**
![ë¼ì¦ˆë² ë¦¬ ë¸Œë ˆë“œë³´ë“œ ë·°](bread.png)
- ë²„íŠ¼ 1 - ìƒí’ˆ ì¸ì‹ + ìœ í†µê¸°í•œ ì¸ì‹
- ë²„íŠ¼ 2 - ìµœì €ê°€ ë¹„êµ
- ë²„íŠ¼ 3 - ë„ì›€ ìš”ì²­
- usb í¬íŠ¸ì— ì‚¬ìš´ë“œ ì¹´ë“œ ì—°ê²° + ì´ì–´í° ì—°ê²° -> ìŒì„±ì¸ì‹ ê°€ëŠ¥

**Arduino bread board view**
![ì•„ë‘ì´ë…¸ ë¸Œë ˆë“œë³´ë“œ ë·°](aa.png)
- ì†¡ì‹ ë¶€

  
---
1. ### ğŸ·ï¸ ìƒí’ˆ ë° ìœ í†µê¸°í•œ ì‹ë³„ - Raspberry pi ( ì½”ë“œ ë³€í•œê±° ë„£ê¸°.)
    ì¹´ë©”ë¼ì— ìƒí’ˆì„ ì¸ì‹í•˜ë©´ **AI í•™ìŠµ**ì„ í†µí•´ ì œí’ˆëª…ì„ ì•Œë ¤ì£¼ê³  ì‹¤ì‹œê°„ìœ¼ë¡œ **ìœ í†µê¸°í•œì„ íŒë…**í•˜ê³  ìƒí’ˆê³¼ ê´€ë ¨í•œ **DB**ë¥¼ í†µí•´ ì‚¬ìš©ìì—ê²Œ ì œí’ˆëª…, ê°€ê²©, ìœ í†µê¸°í•œ ì œê³µ. í•„ìš”ì— ë”°ë¼ ì œí’ˆì— ê´€í•œ ìƒì„¸ì •ë³´ë„ ì œê³µ. ë™ì¼ ì¹´í…Œê³ ë¦¬ë‚´ì—ì„œ ì œí’ˆ êµ¬ë³„.
   
   - ë¼ë²¨ë§ ëœ ì´ë¯¸ì§€ë¥¼ ì´ìš©í•˜ì—¬ AI í•™ìŠµ. (Roboflow, Google colab ì´ìš©)
   - **YOLOv8 ëª¨ë¸**ì„ í†µí•´ ìƒí’ˆì„ ì¸ì‹.  
   - **OCR ê¸°ìˆ **ì„ í™œìš©í•´ ìœ í†µê¸°í•œì„ íŒë…í•˜ê³ , **gTTS ìŒì„± ì•ˆë‚´**ë¡œ ì‚¬ìš©ìì—ê²Œ ì •ë³´ë¥¼ ì œê³µí•©.
   - ìƒí’ˆ ì¸ì‹ í›„ **ë°ì´í„°ë² ì´ìŠ¤**ì—ì„œ ê°€ê²©, ì¹¼ë¡œë¦¬, ì˜ì–‘ ì„±ë¶„ ë“± ì •ë³´ë¥¼ ì¡°íšŒí•˜ì—¬ **ìŒì„±ìœ¼ë¡œ ì¶œë ¥**.

ğŸ‘‰ ìƒí’ˆ ì¸ì‹ ê¸°ëŠ¥ ì„¸ë¶€ ë‚´ìš©(ì½”ë“œ)
  
	- ìƒí’ˆ ì¸ì‹ íŒŒì¼, ìœ í†µê¸°í•œ ì¶”ì¶œ íŒŒì¼, DB íŒŒì¼ ëª¨ë“ˆí™”, mainíŒŒì¼ì—ì„œ ìŠ¤í¬ë¦½íŠ¸ í˜¸ì¶œ
	- ìƒí’ˆì€ ë¼ë©´ì„ ì¤‘ì‹¬ìœ¼ë¡œ (ë„ˆêµ¬ë¦¬, ì§œíŒŒê²Œí‹°, ì‹ ë¼ë©´, ì§„ë¼ë©´, ë¶ˆë‹­ë³¶ìŒë©´) ì½”ë“œ ì‘ì„±
	
<details>
	
   <summary> ìƒí’ˆ YOLOv8 ì¸ì‹ ê´€ë ¨ ì½”ë“œ </summary>
	
```python
from ultralytics import YOLO
from picamera2 import Picamera2
import cv2
import os
from gtts import gTTS
import uuid
import subprocess

def speak(text):
    filename = f"/tmp/tts_{uuid.uuid4()}.mp3"
    tts = gTTS(text=text, lang='ko')
    tts.save(filename)
    subprocess.call(f'mpg123 "{filename}"', shell=True)
    os.remove(filename)

speak("ìƒí’ˆì„ ì¹´ë©”ë¼ ì•ì— ë‚˜ë‘¬ì£¼ì„¸ìš”.")    
model = YOLO("/home/see2407me/ramen.pt")

output_path = "/home/see2407me/result/"
os.makedirs(output_path, exist_ok=True)

cam = Picamera2()
cam.configure(cam.create_video_configuration(main={"format":"XRGB8888","size":(320,240)}))
cam.start()

label_to_kor = {
    "sinlamen": "ì‹ ë¼ë©´",
    "jinramyun": "ì§„ë¼ë©´",
    "nuguri": "ë„ˆêµ¬ë¦¬",
    "jjapagetti": "ì§œíŒŒê²Œí‹°",
    "Firechickenboggummyun": "ë¶ˆë‹­ë³¶ìŒë©´"
}

print("ë¼ë©´ ì¸ì‹ ëª¨ë“œ")

while True:
    frame = cam.capture_array()
    frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2RGB)

    results = model(frame)
    boxes = results[0].boxes

    if len(boxes) > 0:
        cls = int(boxes.cls[0])
        label = model.names[cls]

        kor = label_to_kor.get(label, None)
        if kor:
            with open(output_path + "ramen.txt", "w") as f:
                f.write(label)

            print(f"ë¼ë©´ ì¸ì‹ë¨: {kor}")
            break
    cv2.waitKey(1)

cam.stop()
cv2.destroyAllWindows()
```
</details>

<details>
   <summary> ìœ í†µê¸°í•œ ì¶”ì¶œ íŒŒì¼ ì½”ë“œ </summary>
   
```python
from picamera2 import Picamera2
import pytesseract
import cv2
import re
import os
import time
from gtts import gTTS
import uuid
import subprocess


output_path = "/home/see2407me/result/"
os.makedirs(output_path, exist_ok=True)

def speak(text):
    filename = f"/tmp/tts_{uuid.uuid4()}.mp3"
    tts = gTTS(text=text, lang='ko')
    tts.save(filename)
    subprocess.call(f'mpg123 "{filename}"', shell=True)
    os.remove(filename)

def extract_date(text):
    text = text.replace(" ", "").replace("ê¹Œì§€", "").replace("ìœ í†µê¸°í•œ", "").replace("ì œì¡°", "")
    m = re.search(r"\d{4}\.\d{2}\.\d{2}", text)
    if m:
        return m.group()
    return None

speak("ìœ í†µê¸°í•œì„ ì¸ì‹í•˜ê¸° ìœ„í•´ ìƒí’ˆì„ ëŒë ¤ì£¼ì„¸ìš”.")

cam = Picamera2()
cam.configure(cam.create_video_configuration(main={"format":"XRGB8888","size":(640,480)}))
cam.start()
time.sleep(1)

print("ìë™ ì¸ì‹ëª¨ë“œ ì‹œì‘")

frame_count = 0
max_attempts = 100

while True:
    frame = cam.capture_array()
    frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2RGB)
    cv2.imshow("OCR", frame)

    frame_count += 1
    if frame_count % 8 != 0:
        if cv2.waitKey(1) == ord('q'):
            break
        continue

    print("ì‹œë„ì¤‘..")
    text = pytesseract.image_to_string(frame, lang='kor+eng')
    expiry = extract_date(text)

    if expiry:
        with open(output_path + "expiry.txt", "w") as f:
            f.write(expiry)

        print("ìœ í†µê¸°í•œ:", expiry)
        break
    else:
        print("ìœ í†µê¸°í•œ ì¸ì‹ ì‹¤íŒ¨ : ì¬ì‹œë„ ì¤‘")

    if frame_count > max_attempts:
        speak("ìœ í†µê¸°í•œì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìƒí’ˆ ìœ„ì¹˜ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”.")
        frame_count = 0
        continue
       
    if cv2.waitKey(1) == ord('q'):
        break

cam.stop()
cv2.destroyAllWindows()
```
</details>

<details>
   <summary> ìŒì„± ë° DB ìƒì„¸ì •ë³´ ì½”ë“œ </summary>

```python
# DBë§Œë“¤ê¸°

sqlite3 /home/ìƒì„±í•  DBê²½ë¡œ

CREATE TABLE ramen_info (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    calories INTEGER,
    sodium INTEGER,
    fat REAL,
    carbohydrate REAL,
    protein REAL
);

INSERT INTO ramen_info (name, calories, sodium, fat, carbohydrate, protein) VALUES
('ì§„ë¼ë©´', 500, 1900, 16, 78, 10),
('ì‹ ë¼ë©´', 505, 1890, 17, 80, 9),
('ë„ˆêµ¬ë¦¬', 510, 1940, 18, 76, 8),
('ì§œíŒŒê²Œí‹°', 600, 1200, 21, 90, 10),
('ë¶ˆë‹­ë³¶ìŒë©´', 530, 1600, 20, 85, 11);

.exit  # ë‚˜ê°€ê¸°

UPDATE ramen_info SET sodium = 1950 WHERE name = 'ì‹ ë¼ë©´';  # ë‚´ìš© ë³€ê²½ì‹œ ëª…ë ¹ì–´
ALTER TABLE ramen_info ADD COLUMN price INTEGER;  # ì—´ ì¶”ê°€ (ê°€ê²©)

SELECT * FROM ramen_info;  # ë‚´ìš©í™•ì¸
```

```python
import sqlite3
import os
import time
import uuid
import subprocess
import speech_recognition as sr
from gtts import gTTS

r = sr.Recognizer()
mic = sr.Microphone(device_index=1)

def speak(text):
    """í…ìŠ¤íŠ¸ë¥¼ TTSë¡œ ì½ì–´ì¤Œ"""
    filename = f"/tmp/tts_{uuid.uuid4()}.mp3"
    tts = gTTS(text=text, lang="ko")
    tts.save(filename)
    subprocess.call(f'mpg123 -q "{filename}"', shell=True)
    os.remove(filename)
    time.sleep(1.0)

def format_expiry(expiry):
    """YYYY.MM.DD -> YYYYë…„ MMì›” DDì¼"""
    try:
        y, m, d = expiry.split('.')
        return f"{y}ë…„ {m}ì›” {d}ì¼"
    except:
        return expiry  # í˜¹ì‹œ í¬ë§·ì´ ì´ìƒí•˜ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜

YES_KEYWORDS = ["ì˜ˆ", "ë„¤", "ì‘", "ì¤˜" ,"ê·¸ë˜", "í•´","ì•Œë ¤ì¤˜"]
NO_KEYWORDS = ["ì•„ë‹ˆ", "ì•„ë‹ˆìš”", "ê´œì°®ì•„", "í•„ìš”ì—†ì–´", "ëì–´"]

def recognize_yes_no():
    """ìŒì„± ì¸ì‹ í›„ yes/no/unknown ë°˜í™˜"""
    with mic as source:
        r.adjust_for_ambient_noise(source, duration=0.5)
        try:
            audio = r.listen(source, timeout=5, phrase_time_limit=5)
        except:
            return "unknown"

    try:
        result = r.recognize_google(audio, language="ko-KR")
        print("ì¸ì‹ëœ ìŒì„±:", result)
        if any(k in result for k in YES_KEYWORDS):
            return "yes"
        if any(k in result for k in NO_KEYWORDS):
            return "no"
        return "unknown"
    except:
        return "unknown"

label_to_kor = {
    "shinramen": "ì‹ ë¼ë©´",
    "jinramyun": "ì§„ë¼ë©´",
    "nuguri": "ë„ˆêµ¬ë¦¬",
    "jjapagetti": "ì§œíŒŒê²Œí‹°",
    "buldakbokkeummyun": "ë¶ˆë‹­ë³¶ìŒë©´"
}

with open("/home/see2407me/result/ramen.txt") as f:
    ramen_label = f.read().strip()

kor_name = label_to_kor.get(ramen_label, ramen_label)

with open("/home/see2407me/result/expiry.txt") as f:
    expiry = f.read().strip()

expiry = format_expiry(expiry)

conn = sqlite3.connect("/home/see2407me/ramen.db")
cursor = conn.cursor()
cursor.execute("SELECT * FROM ramen_info WHERE name=?", (kor_name,))
row = cursor.fetchone()
conn.close()

speak(f"ì´ ì œí’ˆì€ {kor_name}ì…ë‹ˆë‹¤.")

if row:
    _, name, cal, sodium, fat, carb, protein, price = row
    speak(f"ê°€ê²©ì€ {price}ì›ì´ê³  ìœ í†µê¸°í•œì€ {expiry}ì…ë‹ˆë‹¤.")

speak("ìƒì„¸ ì •ë³´ë¥¼ ì½ì–´ë“œë¦´ê¹Œìš”? 1ì´ˆ í›„ì— ì‘ ë˜ëŠ” ì•„ë‹ˆë¼ê³  ë§ì”€í•´ì£¼ì„¸ìš”.")

while True:
    answer = recognize_yes_no()

    if answer == "yes" and row:
        speak(
            f"{name}ì˜ ìƒì„¸ ì •ë³´ì…ë‹ˆë‹¤. "
            f"ì—´ëŸ‰ {cal}í‚¬ë¡œì¹¼ë¡œë¦¬, "
            f"íƒ„ìˆ˜í™”ë¬¼ {carb}ê·¸ë¨, "
            f"ì§€ë°© {fat}ê·¸ë¨, "
            f"ë‚˜íŠ¸ë¥¨ {sodium}ë°€ë¦¬ê·¸ë¨, "
            f"ë‹¨ë°±ì§ˆ {protein}ê·¸ë¨ ì…ë‹ˆë‹¤."
        )
        break  # ìƒì„¸ì •ë³´ ì•ˆë‚´ í›„ ë£¨í”„ ì¢…ë£Œ
    elif answer == "no":
        break  # ìƒì„¸ì •ë³´ ì•ˆë‚´ ì—†ì´ ë£¨í”„ ì¢…ë£Œ
    else:
        speak("ëŒ€ë‹µì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.")

```

</details>

<details>
	
   <summary> í†µí•© ì½”ë“œ </summary>
	
```python
from gpiozero import Button
import subprocess
import os
import time
import uuid
import speech_recognition as sr
from gtts import gTTS

r = sr.Recognizer()
mic = sr.Microphone(device_index=1)

YES_WORDS = ["ì˜ˆ", "ë„¤", "ì‘", "ê·¸ë˜", "í•´", "ê³„ì†"]
NO_WORDS = ["ì•„ë‹ˆ", "ì•„ë‹ˆìš”", "ê´œì°®ì•„", "ê·¸ë§Œ", "ì¢…ë£Œ", "ì¤‘ì§€"]

def speak(text):
    print(text)
    filename = f"/tmp/tts_{uuid.uuid4()}.mp3"
    tts = gTTS(text=text, lang="ko")
    tts.save(filename)
    subprocess.call(f'mpg123 -q "{filename}"', shell=True)
    os.remove(filename)
    time.sleep(1.0)

def listen_yes_no():
    with mic as source:
        r.adjust_for_ambient_noise(source, duration=0.5)
        try:
            audio = r.listen(source, timeout=5, phrase_time_limit=5)
        except:
            return ""
    try:
        text = r.recognize_google(audio, language="ko-KR")
        print("ì¸ì‹ëœ ìŒì„±:", text)
        return text
    except:
        return ""

def run_and_wait(cmd):
    return subprocess.call(cmd, shell=True)

while True:

    run_and_wait("python3 /home/see2407me/d.py")
    run_and_wait("python3 /home/see2407me/2.py")
    run_and_wait("python3 /home/see2407me/tts2.py")

    speak("ìƒí’ˆ ì¸ì‹ì„ ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? 1ì´ˆ í›„ì— ì‘ ë˜ëŠ” ì•„ë‹ˆë¼ê³  ë§ì”€í•´ì£¼ì„¸ìš”.")

    while True:
        answer = listen_yes_no()

        if any(word in answer for word in YES_WORDS):
            speak("ìƒí’ˆ ì¸ì‹ì„ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            break
        elif any(word in answer for word in NO_WORDS):
            speak("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            exit()
        else:
            speak("ëŒ€ë‹µì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.")
```
</details>

---
2. ### â• ìµœì €ê°€ ë¹„êµ - Raspberry pi
    ìƒí’ˆì„ ì¸ì‹í•˜ê²Œ ë˜ë©´ ê·¸ **ìƒí’ˆì˜ ìµœì €ê°€ë¥¼ ë„¤ì´ë²„ ê²€ìƒ‰**ì„ í†µí•´ ê²€ìƒ‰ í›„ ì•Œë ¤ì¤Œ.

   - **ë¼ì¦ˆë² ë¦¬ ì¹´ë©”ë¼**ë¥¼ í†µí•´ ìƒí’ˆì„ ì¸ì‹í•¨.
   - ì¸ì‹í•œ ìƒí’ˆì˜ **ë‚±ê°œ ê°€ê²©**ì„ ì‹¤ì‹œê°„ ìŒì„±ìœ¼ë¡œ ì•Œë ¤ì¤Œ.

   [ê²€ìƒ‰ ê³¼ì •]
    ```python      
   - ë„¤ì´ë²„ Open API í™œìš©í•˜ì—¬ ì˜¨ë¼ì¸ ìƒí’ˆ ê°€ê²© ì •ë³´ë¥¼ ì¡°íšŒí•¨
   - ë¼ë©´ 1ë´‰ ê¸°ì¤€ ê°€ê²© ì•ˆë‚´ì´ë¯€ë¡œ, ìƒí’ˆ ì¸ì‹ í›„ [ìƒí’ˆëª… + 1ë´‰] í˜•íƒœë¡œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•¨
   - ê³µí†µëœ ìƒí’ˆëª…ì´ í¬í•¨ëœ ê²½ìš° ë°œìƒí•˜ëŠ” ì˜¤ì¸ì‹ì„ ì¤„ì´ê¸° ìœ„í•´, ì¸ì‹ëœ ìƒí’ˆëª…ì— ë”°ë¼ 
    ```
    
<details>
<summary> ìµœì €ê°€ ê²€ìƒ‰(ì½”ë“œ)</summary>

  ì—¬ê¸°ì— ì ‘íˆëŠ” ë‚´ìš©ì„ ì‘ì„±í•©ë‹ˆë‹¤.
  ì—¬ëŸ¬ ì¤„ë„ ê°€ëŠ¥í•˜ê³  ë§ˆí¬ë‹¤ìš´ë„ ì“¸ ìˆ˜ ìˆì–´ìš”.

```python
  from picamera2 import Picamera2
from ultralytics import YOLO
import cv2
import requests
import os
import time
import uuid
import subprocess
import speech_recognition as sr
from gtts import gTTS

def load_keys():
    with open("naver_key.txt", "r") as f:
        lines = f.read().splitlines()
        return lines[0], lines[1]

CLIENT_ID, CLIENT_SECRET = load_keys()

label_to_kor = {
    "nuguri": "ë„ˆêµ¬ë¦¬",
    "sinlamen": "ì‹ ë¼ë©´",
    "jinramyun": "ì§„ë¼ë©´ ë§¤ìš´ë§›",
    "jjapagetti": "ì§œíŒŒê²Œí‹°",
    "Firechickenboggummyun": "ë¶ˆë‹­ë³¶ìŒë©´",
    "_Carbo": "ê¹Œë¥´ë³´ ë¶ˆë‹­ë³¶ìŒë©´",
    "_Rose": "ë¡œì œ ë¶ˆë‹­ë³¶ìŒë©´"
}

BULDAK_EXCLUDE = ["ë¡œì œ", "ê¹Œë¥´ë³´", "ì¹˜ì¦ˆ", "íƒ•ë©´", "í•µ"]
EXCLUDE_KEYWORDS = ["ìºë¦­í„°", "ë¯¸ë‹ˆì–´ì³", "ë¯¸ë‹ˆì–´ì²˜", "ì†Œí’ˆ", "íŒŒì¸ ", "ëª¨ë°”ì¼ìƒí’ˆê¶Œ", "ëª¨ë°”ì¼ì¿ í°", "ì˜¨ë¼ì¸ìƒí’ˆê¶Œ", "ì˜¨ë¼ì¸ì¿ í°", "ê¸°í”„í‹°ì½˜", "ëª¨í˜•", "í”¼ê·œì–´", "ì¥ë‚œê°"]

YES_WORDS = ["ì˜ˆ", "ì—", "ë„¤", "ì‘", "ê·¸ë˜", "í•´", "ê³„ì†", "í•´ì¤˜"]
NO_WORDS = ["ì•„ë‹ˆ", "ê´œì°®ì•„", "ëì–´", "ì•„ë‹ˆì˜¤", "ê·¸ë§Œ", "ì¢…ë£Œ", "ì¤‘ì§€"]

r = sr.Recognizer()
mic = sr.Microphone(device_index=1)

def speak(text):
    print(text)
    filename = f"/tmp/tts_{uuid.uuid4()}.mp3"
    tts = gTTS(text=text, lang="ko")
    tts.save(filename)
    subprocess.call(f'mpg123 -q "{filename}"', shell=True)
    os.remove(filename)
    time.sleep(0.8)

def listen_yes_no():
    with mic as source:
        r.adjust_for_ambient_noise(source, duration=0.4)
        try:
            audio = r.listen(source, timeout=5, phrase_time_limit=5)
        except:
            return ""
    try:
        text = r.recognize_google(audio, language="ko-KR")
        print("ì¸ì‹ëœ ìŒì„±:", text)
        return text
    except:
        return ""

def map_label_to_kor(label):
    return label_to_kor.get(label)

def search_lowest_price(query, is_buldak):
    url = "https://openapi.naver.com/v1/search/shop.json"
    headers = {
        "X-Naver-Client-Id": CLIENT_ID,
        "X-Naver-Client-Secret": CLIENT_SECRET
    }
    params = {"query": query, "display": 10, "sort": "asc"}
    res = requests.get(url, headers=headers, params=params)
    items = res.json().get("items", [])
    filtered = []
    for item in items:
        title = item["title"]
        if is_buldak and any(x in title for x in BULDAK_EXCLUDE):
            continue
        if any(x in title for x in EXCLUDE_KEYWORDS):
            continue
        filtered.append(item)
    return filtered[0] if filtered else None

def detect_ramen(model, frame):
    if frame.shape[2] == 4:
        frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2RGB)
    else:
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    results = model(frame)
    detected_labels = []

    for r_ in results:
        for box in r_.boxes:
            cls_id = int(box.cls[0])
            label = model.names[cls_id]
            if label in label_to_kor:
                detected_labels.append(label)

    for label in detected_labels:
        if "_Carbo" in label or "_Rose" in label:
            return label

    if "Firechickenboggummyun" in detected_labels:
        return "Firechickenboggummyun"

    return detected_labels[0] if detected_labels else None

def run_once(model, picam2):
    while True:
        frame = picam2.capture_array()
        detected = detect_ramen(model, frame)
        if detected:
            break

    kor_name = map_label_to_kor(detected)
    is_buldak = kor_name == "ë¶ˆë‹­ë³¶ìŒë©´"
    query = f"{kor_name} 1ë´‰"

    speak(f"ê°ì§€ëœ ìƒí’ˆì€ {kor_name}ì…ë‹ˆë‹¤.")
    speak(f"{kor_name}ì˜ ìµœì €ê°€ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.")

    item = search_lowest_price(query, is_buldak)

    if item:
        speak(f"{kor_name}ì˜ ìµœì €ê°€ëŠ” {item['lprice']}ì› ì…ë‹ˆë‹¤.")
    else:
        speak("ìµœì €ê°€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

speak("ìƒí’ˆì„ ì¹´ë©”ë¼ì— ë¹„ì¶”ì–´ ì£¼ì„¸ìš”.")

picam2 = Picamera2()
picam2.configure(picam2.create_preview_configuration(main={"size": (640, 640)}))
picam2.start()

model = YOLO("ramen.pt")

try:
    while True:
        run_once(model, picam2)

        speak("ìµœì €ê°€ ë¹„êµë¥¼ ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? 1ì´ˆ í›„ì— ì‘ ë˜ëŠ” ì•„ë‹ˆë¼ê³  ë§ì”€í•´ì£¼ì„¸ìš”.")

        while True:
            answer_text = listen_yes_no()

            if any(word in answer_text for word in YES_WORDS):
                speak("ìµœì €ê°€ ë¹„êµë¥¼ ê³„ì† ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤. ì›í•˜ì‹œëŠ” ìƒí’ˆì„ ë¹„ì¶°ì£¼ì„¸ìš”.")
                break

            if any(word in answer_text for word in NO_WORDS):
                speak("ìµœì €ê°€ ë¹„êµë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                raise KeyboardInterrupt

            speak("ëŒ€ë‹µì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.")
            time.sleep(0.5)

except KeyboardInterrupt:
    pass
finally:
    picam2.stop()
    del picam2
```
</details>

---
3. ### ğŸš¨ ë„ì›€ ìš”ì²­ ì•ˆë‚´ - Raspberry pi
    ì‚¬ìš©ìê°€ ë„ì›€ì´ í•„ìš”í• ë•Œ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ **ì‚¬ì´íŠ¸ë¥¼ í†µí•´ ì•Œë¦¼**ì„ ë³´ëƒ„.

   - ë²„íŠ¼ì„ í†µí•´ **ì‹¤ì‹œê°„**ìœ¼ë¡œ ë„ì›€ ìš”ì²­ì„ í™•ì¸.
   - **ì¹´ë©”ë¼**ë¥¼ í†µí•´ ì‚¬ìš©ìì˜ ìœ„ì¹˜ë¥¼ í™•ì¸.
   - **ì†Œìš” ì‹œê°„**ê³¼ **ë„ì›€ ìš”ì²­ ì‚¬ìœ **ë¥¼ ê¸°ë¡í•  ìˆ˜ ìˆìŒ.

<details>
<summary>ë„ì›€ ìš”ì²­ ì„œë²„,ì‚¬ì´íŠ¸ (ì½”ë“œ)</summary>

  ì—¬ê¸°ì— ì ‘íˆëŠ” ë‚´ìš©ì„ ì‘ì„±í•©ë‹ˆë‹¤.
  ì—¬ëŸ¬ ì¤„ë„ ê°€ëŠ¥í•˜ê³  ë§ˆí¬ë‹¤ìš´ë„ ì“¸ ìˆ˜ ìˆì–´ìš”.

```python
  from flask import Flask, request, redirect, render_template_string, Response
import requests
from datetime import datetime
import time

app = Flask(__name__)

devices = {}
history = []
clients = []

REASONS = [
    "ë§ˆíŠ¸ì—ì„œ ì´ë™ ë„ì›€",
    "ìƒí’ˆ ì„ íƒ ë„ì›€",
    "ê²°ì œ ë„ì›€",
    "ì¹´íŠ¸ ë„˜ì–´ì§",
    "ì˜¤ì‘ë™",
    "ê¸°íƒ€"
]

def elapsed_time_str(start_time, end_time=None):
    if end_time is None:
        delta = datetime.now() - start_time
    else:
        delta = end_time - start_time
    s = int(delta.total_seconds())
    if s < 60:
        return f"{s}ì´ˆ"
    elif s < 3600:
        return f"{s//60}ë¶„ {s%60}ì´ˆ"
    else:
        return f"{s//3600}ì‹œê°„ {(s%3600)//60}ë¶„"

@app.route("/events")
def sse():
    def gen():
        q = []
        clients.append(q)
        try:
            while True:
                if q:
                    msg = q.pop(0)
                    yield f"data: {msg}\n\n"
                else:
                    time.sleep(0.5)
        except GeneratorExit:
            clients.remove(q)
    return Response(gen(), mimetype="text/event-stream")

@app.route("/")
def index():
    return render_template_string("""
<!DOCTYPE html>
<html lang="ko">
<head>
<meta charset="UTF-8">
<title>ê¸´ê¸‰ ìš”ì²­ ëª¨ë‹ˆí„°</title>
<meta http-equiv="refresh" content="15">
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
body { font-family: sans-serif; background:#f4f6f8; margin:0; padding:16px; }
h1 { margin-bottom: 10px; }
.card { background:#fff; border-radius:12px; padding:16px; margin-bottom:12px; box-shadow:0 2px 6px rgba(0,0,0,0.1); position:relative; }
.badge-new { color:white; background:#d32f2f; padding:4px 10px; border-radius:12px; }
.badge-move { color:white; background:#f57c00; padding:4px 10px; border-radius:12px; }
.btn { display:inline-block; padding:8px 12px; border-radius:6px; color:white; text-decoration:none; margin-right:6px; }
.view { background:#1976d2; }
.move { background:#f57c00; }
.clear { background:#d32f2f; }
.history { background:#eceff1; padding:10px; margin-bottom:10px; border-radius:10px; position:relative; }
.history .delete, .history .edit-btn { position:absolute; right:10px; top:10px; background:#d32f2f; color:white; border:none; padding:3px 6px; border-radius:4px; cursor:pointer; margin-left:4px;}
.history .edit-btn { background:#1976d2; right:60px; }
form { margin:0; }
select, input[type=text] { margin-top:4px; padding:4px 6px; width:200px; border-radius:4px; border:1px solid #ccc; }
</style>

<script>
const evtSource = new EventSource("/events");
evtSource.onmessage = function(event) {
    location.reload();
};
function showReasonForm(deviceId) {
    document.getElementById('reason-form-' + deviceId).style.display = 'block';
}
function toggleOtherInput(sel) {
    const otherInput = sel.parentNode.querySelector('input[name="other_reason"]');
    if(sel.value == 'ê¸°íƒ€') otherInput.style.display='inline-block';
    else otherInput.style.display='none';
}
function showEditForm(idx) {
    document.getElementById('edit-form-' + idx).style.display = 'block';
}
</script>
</head>
<body>

<h1>ê¸´ê¸‰ ìš”ì²­ ëª¨ë‹ˆí„°</h1>

{% for id, d in devices.items() %}
<div class="card">
<b>{{ id }}</b>
<span class="{{ 'badge-new' if d.status=='NEW' else 'badge-move' }}">{{ d.status }}</span><br>
ìš”ì²­ ì‹œê°„: {{ d.time_str }}<br>
ê²½ê³¼ ì‹œê°„: {{ d.elapsed }}<br>
ìš”ì²­ ì‚¬ìœ : {{ d.reason }}<br><br>

<a class="btn view" href="/device/{{ id }}">í™”ë©´ ë³´ê¸°</a>
<a class="btn move" href="/move/{{ id }}">ì§ì› ì´ë™</a>
<a class="btn clear" href="javascript:void(0)" onclick="showReasonForm('{{ id }}')">ì¢…ë£Œ</a>

<div id="reason-form-{{ id }}" style="display:none; margin-top:8px;">
<form action="/clear/{{ id }}" method="post">
<select name="reason" onchange="toggleOtherInput(this)">
{% for r in reasons %}
<option value="{{ r }}">{{ r }}</option>
{% endfor %}
</select>
<input type="text" name="other_reason" placeholder="ì§ì ‘ ì…ë ¥" style="display:none;">
<input type="submit" value="í™•ì¸">
</form>
</div>
</div>
{% else %}
<p>í˜„ì¬ ìš”ì²­ì´ ì—†ìŠµë‹ˆë‹¤.</p>
{% endfor %}

<hr>

<h1>ìš”ì²­ ê¸°ë¡</h1>
{% for idx, h in enumerate(history) %}
<div class="history">
<b>{{ h.device_id }}</b><br>
ì‹œì‘ ì‹œê°„: {{ h.start_time }}<br>
ì¢…ë£Œ ì‹œê°„: {{ h.end_time }}<br>
ì†Œìš” ì‹œê°„: {{ h.duration }}<br>
ì‚¬ìœ : {{ h.reason }}

<form action="/delete_history/{{ idx }}" method="post" style="display:inline;">
<button class="delete">ì‚­ì œ</button>
</form>

<button class="edit-btn" onclick="showEditForm({{ idx }})">ìˆ˜ì •</button>

<div id="edit-form-{{ idx }}" style="display:none; margin-top:4px;">
<form action="/edit_reason/{{ idx }}" method="post">
<select name="reason" onchange="toggleOtherInput(this)">
{% for r in reasons %}
<option value="{{ r }}" {% if r==h.reason %}selected{% endif %}>{{ r }}</option>
{% endfor %}
</select>
<input type="text" name="other_reason" value="{% if h.reason not in reasons %}{{ h.reason }}{% endif %}">
<input type="submit" value="í™•ì¸">
</form>
</div>

</div>
{% else %}
<p>ìš”ì²­ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.</p>
{% endfor %}

</body>
</html>
""",
devices={k: {
    **v,
    "elapsed": elapsed_time_str(v["time"]),
    "time_str": v["time"].strftime("%Y-%m-%d %H:%M:%S")
} for k,v in devices.items()},
history=history,
reasons=REASONS,
enumerate=enumerate
)

@app.route("/device/<device_id>")
def view_device(device_id):
    d = devices.get(device_id)
    if not d:
        return "í•´ë‹¹ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", 404
    return f"""
<html>
<head><meta charset="UTF-8"></head>
<body style="background:black;color:white;text-align:center">
<h2>{device_id} ìš”ì²­ í™”ë©´</h2>
<iframe src="{d['stream_url']}" width="720" height="540"></iframe><br><br>
<a href="/" style="color:white">â† ëŒì•„ê°€ê¸°</a>
</body>
</html>
"""

@app.route("/emergency", methods=["POST"])
def emergency():
    data = request.get_json(silent=True)
    if not data:
        return "Invalid JSON", 400

    device_id = str(data.get("device_id"))
    stream_url = str(data.get("stream_url"))
    reason = str(data.get("reason", "ê¸°íƒ€"))

    devices[device_id] = {
        "stream_url": stream_url,
        "status": "NEW",
        "time": datetime.now(),
        "reason": reason
    }
    for q in clients:
        q.append("update")

    return "OK", 200


@app.route("/move/<device_id>")
def move_staff(device_id):
    d = devices.get(device_id)
    if not d:
        return "Not found", 404
    try:
        requests.get(d["stream_url"] + "/staff_moving", timeout=2)
    except:
        pass
    d["status"] = "MOVING"
    return redirect("/")

@app.route("/clear/<device_id>", methods=["POST"])
def clear(device_id):
    d = devices.get(device_id)
    if d:
        try:
            requests.get(d["stream_url"] + "/stop", timeout=1)
        except:
            pass

        reason = request.form.get("reason")
        other_reason = request.form.get("other_reason")

        if reason == "ê¸°íƒ€" and other_reason.strip():
            reason = other_reason.strip()

        end_time = datetime.now()

        history.insert(0, {
            "device_id": device_id,
            "start_time": d["time"].strftime("%Y-%m-%d %H:%M:%S"),
            "end_time": end_time.strftime("%Y-%m-%d %H:%M:%S"),
            "duration": elapsed_time_str(d["time"], end_time),
            "reason": reason
        })

        devices.pop(device_id, None)

    return redirect("/")

@app.route("/edit_reason/<int:idx>", methods=["POST"])
def edit_reason(idx):
    if 0 <= idx < len(history):
        reason = request.form.get("reason")
        other_reason = request.form.get("other_reason")
        if reason == "ê¸°íƒ€" and other_reason.strip():
            reason = other_reason.strip()
        history[idx]["reason"] = reason
    return redirect("/")

@app.route("/delete_history/<int:idx>", methods=["POST"])
def delete_history(idx):
    if 0 <= idx < len(history):
        history.pop(idx)
    return redirect("/")

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=False)
```
</details>

<details>
<summary>ë„ì›€ ìš”ì²­ ë””ë°”ì´ìŠ¤ (ì½”ë“œ)</summary>

  ì—¬ê¸°ì— ì ‘íˆëŠ” ë‚´ìš©ì„ ì‘ì„±í•©ë‹ˆë‹¤.
  ì—¬ëŸ¬ ì¤„ë„ ê°€ëŠ¥í•˜ê³  ë§ˆí¬ë‹¤ìš´ë„ ì“¸ ìˆ˜ ìˆì–´ìš”.

```python

import io
import threading
import requests
import socketserver
import os
import time
from threading import Condition
from http import server
import speech_recognition as sr

from picamera2 import Picamera2
from PIL import Image

# ğŸ”Š TTS
from gtts import gTTS
from pygame import mixer

DEVICE_ID = "CAM_01"
DEVICE_IP = "172.20.10.4"
CENTRAL_SERVER = "http://172.20.10.4:5000"
STREAM_PORT = 8000

def speak(text):
    try:
        print("ğŸ”Š TTS:", text)
        tts = gTTS(text=text, lang="ko")
        filename = "tts.mp3"
        tts.save(filename)

        mixer.init()
        mixer.music.load(filename)
        mixer.music.play()

        while mixer.music.get_busy():
            time.sleep(0.1)

        mixer.quit()
        os.remove(filename)

    except Exception as e:
        print("âš ï¸ TTS ì˜¤ë¥˜:", e)


def recognize_speech():
    r = sr.Recognizer()

    # ğŸ”¹ ìŒì„± ì¸ì‹ ì‹œì‘ ì „ ì•ˆë‚´ ë©˜íŠ¸
    speak("ìš”ì²­ ì‚¬í•­ì„ 1ì´ˆ ë’¤ì— ë§ì”€í•´ ì£¼ì‹œë©´ ì‹ ì†í•˜ê²Œ ëŒ€ì‘í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")

    with sr.Microphone() as source:
        print("ë§í•˜ì„¸ìš”")
        try:
            audio = r.listen(source, timeout=5)
        except sr.WaitTimeoutError:
            print("âš ï¸ ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

    try:
        text = r.recognize_google(audio, language="ko-KR")
        print("ì¸ì‹ ê²°ê³¼:", text)
        return text
    except:
        print("âš ï¸ ìŒì„± ì¸ì‹ ì‹¤íŒ¨")
        return None

HTML_PAGE = """
<!DOCTYPE html>
<html lang="ko">
<head>
<meta charset="UTF-8">
<title>Camera Stream</title>
</head>
<body style="background:black;color:white;text-align:center">
<h1>ìš”ì²­ì ì‹¤ì‹œê°„ ì˜ìƒ</h1>
<img src="stream.mjpg" width="640" height="480">
</body>
</html>
"""

class StreamingOutput:
    def __init__(self):
        self.frame = None
        self.condition = Condition()

    def write(self, data):
        with self.condition:
            self.frame = data
            self.condition.notify_all()

class StreamingHandler(server.BaseHTTPRequestHandler):
    def do_GET(self):

        if self.path == "/stop":
            self.send_response(200)
            self.end_headers()
            self.wfile.write(b"STOP")
            print("STOP received. Exiting.")
            os._exit(0)
            return

        if self.path == "/staff_moving":
            self.send_response(200)
            self.end_headers()
            self.wfile.write(b"STAFF MOVING")
            print("Staff is on the way")

            # ğŸ”¹ ì§ì› ì´ë™ ì¤‘ ìŒì„± ì•ˆë‚´ (ìŠ¤íŠ¸ë¦¬ë° ëŠê¹€ ë°©ì§€ìš© ìŠ¤ë ˆë“œ)
            threading.Thread(
                target=speak,
                args=("ì§ì›ì´ ì´ë™ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.",),
                daemon=True
            ).start()
            return

        if self.path in ("/", "/index.html"):
            content = HTML_PAGE.encode("utf-8")
            self.send_response(200)
            self.send_header("Content-Type", "text/html")
            self.send_header("Content-Length", len(content))
            self.end_headers()
            self.wfile.write(content)
            return

        if self.path == "/stream.mjpg":
            self.send_response(200)
            self.send_header(
                "Content-Type",
                "multipart/x-mixed-replace; boundary=FRAME"
            )
            self.end_headers()
            try:
                while True:
                    with output.condition:
                        output.condition.wait()
                        frame = output.frame

                    self.wfile.write(b"--FRAME\r\n")
                    self.send_header("Content-Type", "image/jpeg")
                    self.send_header("Content-Length", len(frame))
                    self.end_headers()
                    self.wfile.write(frame)
                    self.wfile.write(b"\r\n")
            except Exception:
                pass
            return

        self.send_error(404)

class StreamingServer(socketserver.ThreadingMixIn, server.HTTPServer):
    allow_reuse_address = True
    daemon_threads = True


picam2 = Picamera2()

config = picam2.create_video_configuration(
    main={
        "size": (640, 480),
        "format": "RGB888"
    }
)

picam2.configure(config)
picam2.set_controls({"AwbEnable": True})
picam2.start()

output = StreamingOutput()

def capture_loop():
    while True:
        frame = picam2.capture_array()
        frame = frame[:, :, ::-1]
        image = Image.fromarray(frame, "RGB")
        buf = io.BytesIO()
        image.save(buf, format="JPEG")
        output.write(buf.getvalue())

def register_device():
    reason_text = recognize_speech()

    data = {
        "device_id": DEVICE_ID,
        "stream_url": "http://" + DEVICE_IP + ":" + str(STREAM_PORT),
        "reason": reason_text if reason_text else "ìŒì„± ì¸ì‹ ì‹¤íŒ¨"
    }

    print("ì„œë²„ë¡œ ì „ì†¡:", data)
    requests.post(CENTRAL_SERVER + "/emergency", json=data)


if __name__ == "__main__":
    threading.Thread(target=capture_loop, daemon=True).start()
    register_device()

    server = StreamingServer(("", STREAM_PORT), StreamingHandler)
    print("Streaming started on port", STREAM_PORT)
    server.serve_forever()

```
</details>

#### ğŸ“ Raspberry piì˜ ë©”ì¸ ì½”ë“œ (ìƒí’ˆ ì¸ì‹ + ìµœì €ê°€ ë¹„êµ + ë„ì›€ìš”ì²­)
- ë²„íŠ¼ì„ í†µí•´ ì›í•˜ëŠ” ê¸°ëŠ¥ì„ ë¶ˆëŸ¬ì˜¤ë„ë¡ í•˜ëŠ” ì½”ë“œ (í˜¸ì¶œ)

<details>
<summary>ì „ì²´ main ì½”ë“œ</summary>

```python
from gpiozero import Button
import subprocess
import time
import socket
import threading
import os
import uuid
import signal
from signal import pause
from gtts import gTTS
import board
import busio
import adafruit_bno055


BTN_SCAN  = Button(17, pull_up=True, bounce_time=0.3)
BTN_PRICE = Button(27, pull_up=True, bounce_time=0.3)
BTN_HELP  = Button(22, pull_up=True, bounce_time=0.3)


SERVER_PATH = "/home/see2407me/server.py"
SERVER_IP = "172.20.10.4"
SERVER_PORT = 5000

def is_port_open(ip, port):
    try:
        s = socket.socket()
        s.settimeout(1)
        s.connect((ip, port))
        s.close()
        return True
    except:
        return False

if not is_port_open(SERVER_IP, SERVER_PORT):
    print("ğŸš€ ì„œë²„ í™•ì¸ ì¤‘...")
    try:
        subprocess.Popen(["python3", SERVER_PATH])
        time.sleep(2)
    except:
        pass


def speak(text):
    def _speak(text):
        try:
            filename = f"/tmp/tts_{uuid.uuid4()}.mp3"
            gTTS(text=text, lang="ko").save(filename)
            subprocess.run(["mpg123", "-q", filename], check=True)
            if os.path.exists(filename):
                os.remove(filename)
        except Exception as e:
            print(f"TTS Error: {e}")
    threading.Thread(target=_speak, args=(text,), daemon=True).start()


def init_imu():
    try:
        i2c = busio.I2C(board.SCL, board.SDA)
        sensor = adafruit_bno055.BNO055_I2C(i2c)
        print("âœ… IMU ì„¼ì„œ ì—°ê²° ì„±ê³µ")
        return sensor
    except Exception as e:
        print(f"âš ï¸ IMU ì„¼ì„œ ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

imu = init_imu()

TILT_THRESHOLD = 9.65
RECOVER_THRESHOLD = 3.0
tilt_active = False
fall_event = threading.Event()


FALL_ALERT_FILE = "/tmp/fall_alert.flag"

# ì´ˆê¸° ìƒíƒœ: íŒŒì¼ ìˆìœ¼ë©´ í™œì„±, ì—†ìœ¼ë©´ ë¹„í™œì„±
if not os.path.exists(FALL_ALERT_FILE):
    with open(FALL_ALERT_FILE, "w") as f:
        f.write("1")

def check_fall_alert():
    return os.path.exists(FALL_ALERT_FILE)

def reset_fall_alert():
    with open(FALL_ALERT_FILE, "w") as f:
        f.write("1")
    print("âœ… IMU ì•ŒëŒ ë‹¤ì‹œ í™œì„±í™”")


current_process = None
process_lock = threading.Lock()

def kill_current_process_and_wait():
    global current_process
    with process_lock:
        if current_process and current_process.poll() is None:
            print("â›” ê¸°ì¡´ ì‘ì—… ì¢…ë£Œ ë° ì¹´ë©”ë¼ í•´ì œ ì¤‘...")
            try:
                pgid = os.getpgid(current_process.pid)
                os.killpg(pgid, signal.SIGTERM)
                for _ in range(20):
                    if current_process.poll() is not None:
                        break
                    time.sleep(1.1)
                if current_process.poll() is None:
                    os.killpg(pgid, signal.SIGKILL)
                    current_process.wait()
            except ProcessLookupError:
                pass
            current_process = None
    time.sleep(2.0)

def run_process(path, voice=None):
    kill_current_process_and_wait()
    if voice:
        speak(voice)
    global current_process
    with process_lock:
        try:
            current_process = subprocess.Popen(
                ["python3", path],
                preexec_fn=os.setsid
            )
        except Exception as e:
            print(f"ì‹¤í–‰ ì‹¤íŒ¨: {e}")

def run_manual_help():
    run_process("/home/see2407me/device.py", "ë„ì›€ ìš”ì²­ì„ ë³´ëƒˆìŠµë‹ˆë‹¤.")

def run_fall_help_safe():
    print("ğŸš¨ [ë„˜ì–´ì§ ê°ì§€] ë„ì›€ ìš”ì²­ ì‹œì‘")
   
    # IMU ì•ŒëŒ ì ì‹œ ë¹„í™œì„±í™” â†’ í”Œë˜ê·¸ íŒŒì¼ ì‚­ì œ
    if os.path.exists(FALL_ALERT_FILE):
        os.remove(FALL_ALERT_FILE)
   
    kill_current_process_and_wait()
    speak("ì¹´íŠ¸ê°€ ë„˜ì–´ì¡ŒìŠµë‹ˆë‹¤. ë„ì›€ì„ ìš”ì²­í•©ë‹ˆë‹¤.")
    time.sleep(2.0)
   
    try:
        # ğŸ”¥ blocking call: device2.py ì¢…ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼
        subprocess.call(["python3", "/home/see2407me/device2.py"])
    except Exception as e:
        print(f"ë„ì›€ ìš”ì²­ ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
   
    # ì¢…ë£Œ í›„ í”Œë˜ê·¸ ë³µì› â†’ IMU ì¬ê°ì§€ ê°€ëŠ¥
    reset_fall_alert()

def imu_watch_loop():
    global tilt_active, imu
    consecutive_none = 0
    while True:
        fall_alert_active = check_fall_alert()  # ë§¤ ë£¨í”„ë§ˆë‹¤ ìƒíƒœ í™•ì¸

        if imu is None:
            imu = init_imu()
            if imu is None:
                time.sleep(5)
                continue
        try:
            gravity = imu.gravity
            if gravity and gravity[1] is not None:
                gy = gravity[1]
                consecutive_none = 0

                if abs(gy) > TILT_THRESHOLD and not tilt_active and fall_alert_active:
                    tilt_active = True
                    fall_event.set()
                elif abs(gy) < RECOVER_THRESHOLD:
                    tilt_active = False
            else:
                consecutive_none += 1
                if consecutive_none > 3:
                    imu = None
        except:
            imu = None
        time.sleep(0.2)

def fall_handler_loop():
    while True:
        fall_event.wait()
        fall_event.clear()
        run_fall_help_safe()

BTN_SCAN.when_pressed  = lambda: run_process("/home/see2407me/text4.py", "ìƒí’ˆ ì¸ì‹ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
BTN_PRICE.when_pressed = lambda: run_process("/home/see2407me/price8.py", "ìµœì €ê°€ ë¹„êµë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
BTN_HELP.when_pressed  = run_manual_help

if __name__ == "__main__":
    print("âœ… ì¹´íŠ¸ ì‹œìŠ¤í…œ ê°€ë™ ì¤‘...")
    threading.Thread(target=imu_watch_loop, daemon=True).start()
    threading.Thread(target=fall_handler_loop, daemon=True).start()
    try:
        pause()  # ë²„íŠ¼ ì´ë²¤íŠ¸ ë° ìŠ¤ë ˆë“œ ê³„ì† ìœ ì§€
    except KeyboardInterrupt:
        kill_current_process_and_wait()
        print("\nğŸ‘‹ ì‹œìŠ¤í…œ ì¢…ë£Œ")

```
</details>

---
4. ### ğŸš§ ì‹¤ì‹œê°„ ì¥ì• ë¬¼ ê°ì§€- Arduino
    ì¥ì• ë¬¼ì´ ì¹´íŠ¸ ì•ì— ìœ„ì¹˜í•  ê²½ìš° ì„ê³„ê±°ë¦¬ë¥¼ ì„¤ì •í•˜ì—¬ ì„ê³„ê±°ë¦¬ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜¤ë©´, ì†ëª©ë°´ë“œì˜ ì§„ë™ì„ ì´ìš©í•´ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼. **ì¥ì• ë¬¼ ê±°ë¦¬ì— ë”°ë¼ ì§„ë™ ì†ë„ë¥¼ ë‹¤ë¥´ê²Œ í•˜ì—¬ ìœ„í—˜ë„**ë¥¼ í‘œí˜„.

   - **ì•„ë‘ì´ë…¸ ìš°ë…¸ + ê±°ë¦¬ ì„¼ì„œ**ë¥¼ í™œìš©í•´ ì „ë°© ì¥ì• ë¬¼ ê±°ë¦¬ ì¸¡ì •.
   - **ë¬´ì„ í†µì‹ ëª¨ë“ˆ + ì–´ë‹µí„°**ì„ í†µí•´ ì¥ì• ë¬¼ì— ë”°ë¥¸ ì‹ í˜¸ ì†¡ìˆ˜ì‹ .
   - **ì•„ë‘ì´ë…¸ ë‚˜ë…¸ + ì§„ë™ëª¨ë“ˆ**ì„ ì´ìš©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì‹¤ì‹œê°„ìœ¼ë¡œ ìœ„í—˜ë„ë¥¼ ì•Œë¦¼.
   - **ìŠ¤ìœ„ì¹˜**ë¥¼ í†µí•´ ì§„ë™ **ì˜¨ì˜¤í”„** ë° **ì „ì› ì˜¨ì˜¤í”„**

<details>
<summary>ì¥ì• ë¬¼ ê°ì§€ ê¸°ëŠ¥ ì†¡ì‹ ë‹¨(ì½”ë“œ)</summary>

  ê±°ë¦¬ ì„¼ì„œì—ì„œ ì¥ì• ë¬¼ ì¸¡ì • í›„ ì‹ í˜¸ ì†¡ì‹ .
  **ìµœëŒ€ê±°ë¦¬ ì„ê³„ ê±°ë¦¬ 800cm** ì´í•˜ë©´ ì¥ì• ë¬¼ì´ ìˆìŒì„ ì¸ì‹ .

```python
#include <Wire.h>
#include <Adafruit_VL53L0X.h>
#include <SPI.h>
#include <nRF24L01.h>
#include <RF24.h>

Adafruit_VL53L0X lox = Adafruit_VL53L0X();

// nRF24
RF24 radio(9, 10);                 // CE, CSN
const byte address[6] = "00001";

// ìµœëŒ€ ê±°ë¦¬ (ì´ ì´ìƒì€ ì§„ë™ X)
const int MAX_DISTANCE_MM = 800;   // 80 cm

void setup() {
  Serial.begin(9600);
  Serial.println("TX START");

  Wire.begin();
  if (!lox.begin()) {
    Serial.println("VL53L0X ì¸ì‹ ì‹¤íŒ¨");
    while (1);
  }
  Serial.println("VL53L0X OK");

  radio.begin();
  radio.openWritingPipe(address);
  radio.setPALevel(RF24_PA_LOW);
  radio.stopListening();            // ì†¡ì‹  ëª¨ë“œ
}

void loop() {
  VL53L0X_RangingMeasurementData_t measure;
  lox.rangingTest(&measure, false);

  if (measure.RangeStatus != 4) {   // ì •ìƒ ì¸¡ì •
    int distance = measure.RangeMilliMeter;

    // ë„ˆë¬´ ë¨¼ ê°’ì€ ì»·
    if (distance > MAX_DISTANCE_MM) {
      distance = MAX_DISTANCE_MM;
    }

    radio.write(&distance, sizeof(distance));

    Serial.print("Distance TX: ");
    Serial.print(distance);
    Serial.println(" mm");
  }

  delay(100);
}

```
</details>

<details>
<summary>ì¥ì• ë¬¼ ê°ì§€ ê¸°ëŠ¥ ìˆ˜ì‹ ë‹¨(ì½”ë“œ)</summary>

  ì†¡ì‹ ë‹¨ì—ì„œ ë°›ì€ ì‹ í˜¸ë¡œ ì§„ë™ëª¨ë“ˆì„ í†µí•´ ì‚¬ìš©ìì—ì„¸ ì¥ì• ë¬¼ ì•Œë¦¼.
  ê±°ë¦¬ì— ë”°ë¼ ì§„ë™ íšŸìˆ˜ ë³€ë™í•˜ì—¬ ê°€ê¹Œìš´ ì¥ì• ë¬¼ì„ ì•Œë ¤ì¤Œ.

```python
#include <SPI.h>
#include <nRF24L01.h>
#include <RF24.h>

#define CE_PIN     9
#define CSN_PIN    10
#define MOTOR_PIN  3 // ìŠ¤ìœ„ì¹˜ê°€ ëª¨í„°ì— ì§ì ‘ ì—°ê²°ë˜ì—ˆìœ¼ë¯€ë¡œ SWITCH_PINì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

RF24 radio(CE_PIN, CSN_PIN);
const byte address[6] = "00001";

const int MIN_DISTANCE = 50;     // 5 cm
const int MAX_DISTANCE = 800;    // 80 cm
const unsigned long MIN_INTERVAL = 80;
const unsigned long MAX_INTERVAL = 600;

unsigned long lastToggleTime = 0;
unsigned long vibrationInterval = 0;

bool motorState = false;

int currentDistance = MAX_DISTANCE;
bool hasReceived = false;

void initRadio() {

  if (radio.begin()) {
    radio.openReadingPipe(0, address);
    radio.setPALevel(RF24_PA_LOW);

    radio.startListening();

    Serial.println(">>> Radio Initialized & Listening...");
  } else {
    Serial.println(">>> Radio Hardware Error!");
  }
}

void setup() {

  Serial.begin(9600);
  pinMode(MOTOR_PIN, OUTPUT);
  digitalWrite(MOTOR_PIN, LOW);

  initRadio();
  Serial.println("RX SYSTEM START (Motor Switch Mode)");
}
void loop() {

  // 1. ğŸ“¡ ë°ì´í„° ìˆ˜ì‹  ì‹œë„ (í•­ìƒ ì‘ë™)
  if (radio.available()) {
    radio.read(&currentDistance, sizeof(currentDistance));
    hasReceived = true;

    if (currentDistance >= MAX_DISTANCE) {
      vibrationInterval = 0;

    } else {
      vibrationInterval = map(currentDistance, MIN_DISTANCE, MAX_DISTANCE, MIN_INTERVAL, MAX_INTERVAL);
      vibrationInterval = constrain(vibrationInterval, MIN_INTERVAL, MAX_INTERVAL);
    }
    Serial.print("Dist: "); Serial.print(currentDistance);
    Serial.print("mm | Inter: "); Serial.println(vibrationInterval);
  }

  // 2. ğŸ”” ì§„ë™ ì‹ í˜¸ ì¶œë ¥ (ëª¨í„° ìŠ¤ìœ„ì¹˜ì™€ ìƒê´€ì—†ì´ ì•„ë‘ì´ë…¸ëŠ” ì‹ í˜¸ë¥¼ ê³„ì† ë³´ëƒ„)
  if (hasReceived && vibrationInterval > 0) {
    unsigned long now = millis();
    if (now - lastToggleTime >= vibrationInterval) {
      lastToggleTime = now;
      motorState = !motorState;
      digitalWrite(MOTOR_PIN, motorState);
    }

  } else {
    digitalWrite(MOTOR_PIN, LOW);
    motorState = false;
  }
}

```
</details>

---
## ì™„ì„± ëª¨í˜•
### ì‹œì—° ì˜ìƒ ë° ì‚¬ì§„
**Raspberry pi**ì˜ ì‹œì—° ì‚¬ì§„

- ìƒí’ˆ ì¸ì‹
  
  [ìƒí’ˆì¸ì‹ ë™ì‘ íë¦„]
  
  ```python
    1. ë¼ì¦ˆë² ë¦¬ì¹´ë©”ë¼ë¡œ ìƒí’ˆ ì´¬ì˜
    2. YOLO í•™ìŠµì„ ë°”íƒ•ìœ¼ë¡œ ìƒí’ˆì„ ì¸ì‹í•˜ì—¬ ì¢…ë¥˜ íŒë³„ í›„ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
    3. ìƒí’ˆì„ ëŒë ¤ë‹¬ë¼ëŠ” ì•ˆë‚´ ë¬¸êµ¬ ì¶œë ¥ -> ì´ë¯¸ì§€ ì „ì²˜ë¦¬, OCRì„ í†µí•´ ìœ í†µê¸°í•œ ì¶”ì¶œ í›„ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
    4. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í•´ë‹¹ ìƒí’ˆ ì„±ë¶„í‘œ ì œê³µ (ì‚¬ìš©ì ìŒì„±ì…ë ¥ìœ¼ë¡œ ì•Œë¦¼ ì—¬ë¶€ ì œì–´ ê°€ëŠ¥)
    5. ì‚¬ìš©ì ìŒì„±ì…ë ¥ìœ¼ë¡œ ì „ì²´ ìƒí’ˆì¸ì‹ ê¸°ëŠ¥ ë°˜ë³µ ì—¬ë¶€ë¥¼ ê²°ì •.
   ```
   [ì‹¤í–‰ ê²°ê³¼]
  
  ![ìƒí’ˆ ì¸ì‹ ê³¼ì •](cam.png)

 - ìµœì €ê°€ ë¹„êµ
   
   [ìµœì €ê°€ ë™ì‘ íë¦„]

   ```python
   1. ì¹´ë©”ë¼ë¡œ ìƒí’ˆì„ ì¸ì‹í•˜ì—¬ ì¢…ë¥˜ íŒë³„
   2. í•´ë‹¹ ì œí’ˆì„ ë„¤ì´ë²„ì— ê²€ìƒ‰
   3. ê²€ìƒ‰í•˜ì—¬ ë‚˜ì˜¤ëŠ” ìƒí’ˆ ì •ë³´ ì¤‘ ìƒí’ˆ ê°€ê²© ìµœì €ê°€ë¥¼ ì‚¬ìš©ìì—ê²Œ ttsë¡œ ì•ˆë‚´
  
   ```
   [ì‹¤í–‰ ê²°ê³¼]
   
   ![ìµœì €ê°€ ë¹„êµ ê³¼ì •](price.png) 

- ë„ì›€ ìš”ì²­

   [ë„ì›€ ìš”ì²­ íë¦„]

  ```python
   1. ì‚¬ìš©ìê°€ ì‡¼í•‘ ì¤‘ ë„ì›€ì´ í•„ìš”í•  ê²½ìš° ë„ì›€ìš”ì²­ ë²„íŠ¼ì„ ëˆ„ë¦„
   2. ì‚¬ì´íŠ¸ì— ë„ì›€ìš”ì²­ ì•Œë¦¼ ì‹¤ì‹œê°„ ì „ì†¡
   3. â€˜í™”ë©´ ë³´ê¸°â€™ íƒ­ì„ í†µí•´ ì¹´íŠ¸ì— ì„¤ì¹˜ëœ ë¼ì¦ˆë² ë¦¬ ì¹´ë©”ë¼ì˜ ì˜ìƒì„ í™•ì¸í•˜ì—¬ 
   4.  ì‹¤ì‹œê°„ìœ¼ë¡œ ì‚¬ìš©ìì˜ ìœ„ì¹˜ íŒŒì•… ê°€ëŠ¥
   5. â€˜ì§ì› ì´ë™â€™ íƒ­ ì„ íƒ ì‹œ ë‹´ë‹¹ ì§ì›ì´ ì´ë™ ì¤‘ì„ì„ ì‚¬ìš©ìì—ê²Œ tts ìŒì„±ìœ¼ë¡œ ì•ˆë‚´
   6. â€˜ì¢…ë£Œâ€™ íƒ­ì„ ëˆ„ë¥´ë©´ ë„ì›€ ìš”ì²­ì´ ì¢…ë£Œë˜ë©°, ìš”ì²­ ì‚¬ìœ ì™€ ì²˜ë¦¬ ì†Œìš” ì‹œê°„ì´ ê¸°ë¡ë¨

  ```
   [ì‹¤í–‰ ê²°ê³¼]
 
  ![ë„ì›€ ìš”ì²­ ê³¼ì •](help.png) 

 - 1ë²ˆ ì‚¬ì§„ : ì‚¬ìš©ìê°€ ë„ì›€ìš”ì²­ ë²„íŠ¼ì„ ëˆ„ë¥¼ ì‹œ ì‚¬ì´íŠ¸ì— ì‹¤ì‹œê°„ìœ¼ë¡œ ì•Œë¦¼ ì „ì†¡
 - 2ë²ˆ ì‚¬ì§„ : â€˜í™”ë©´ ë³´ê¸°â€™ íƒ­ì„ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì‚¬ìš©ìì˜ ìœ„ì¹˜ íŒŒì•… ê°€ëŠ¥
 - 3ë²ˆ ì‚¬ì§„ : â€˜ì§ì› ì´ë™â€™ íƒ­ ì„ íƒ ì‹œ ë‹´ë‹¹ ì§ì›ì´ ì´ë™ ì¤‘ì„ì„ ì‚¬ìš©ìì—ê²Œ tts ìŒì„±ìœ¼ë¡œ ì•ˆë‚´í•˜ê³  ë„ì›€ ìš”ì²­ ì‚¬ìœ  ì„ íƒ ë° ì§ì ‘ ì…ë ¥ ê°€ëŠ¥
 - 4ë²ˆ ì‚¬ì§„ : â€˜ì¢…ë£Œâ€™ íƒ­ì„ ëˆ„ë¥´ë©´ ë„ì›€ ìš”ì²­ì´ ì¢…ë£Œë˜ë©°, ìš”ì²­ ì‚¬ìœ ì™€ ì²˜ë¦¬ ì†Œìš” ì‹œê°„ì´ ê¸°ë¡ë¨ 

---

## ë³´ì•ˆí•  ì 

---
## ê¸°ëŒ€ íš¨ê³¼

- **ì‹œê°ì¥ì• ì¸ì˜ ììœ¨ì ì¸ ì‡¼í•‘ í™˜ê²½ ì œê³µ**  
- **ì¶©ëŒ ë°©ì§€ë¥¼ í†µí•œ ì•ˆì „ì„± í™•ë³´**  
- **ì‚¬íšŒì  ì•½ì ë°°ë ¤ ê¸°ìˆ ë¡œì„œì˜ í™•ì¥ì„±**  
- **ë‹¤ì–‘í•œ ìœ í†µ í™˜ê²½ì— ì ìš© ê°€ëŠ¥í•œ ë²”ìš© ëª¨ë“ˆ**

---
